\documentclass[a4paper, natbib, doc, 12pt]{apa7}

% Packages
    \usepackage[T1]{fontenc}
    \usepackage[utf8]{inputenc}
    \usepackage{geometry}
    \geometry{
    left=1in,
    right=1in,
    bottom=1.5in,}

    \usepackage[english]{babel}
    \usepackage{amsmath}
    \usepackage{graphicx}
    \usepackage{url}
    \usepackage{natbib}
    \usepackage{authblk}
    % \usepackage[usenames,dvipsnames]{xcolor}
    % \usepackage{setspace}
    % \usepackage{hyperref}

    % \usepackage{fancyhdr}
    % \pagestyle{fancy}
    % \fancyhead[L]{MELANOMA PERCEPTUAL FEATURES}
    % \fancyhead[R]{}
    % \fancyfoot[C]{\thepage}

    % \usepackage{lmodern}
    % \usepackage[draft, obeyFinal, bordercolor=gray, backgroundcolor=white, linecolor=red]{todonotes}

    % Replace 'draft' with 'final' to remove all comments.
    \newcommand{\Note}[1]{\todo[inline]{#1}}
    % \usepackage{xargs}

    \interfootnotelinepenalty=10000
    \raggedbottom

    \def\linkosf{\rm{\url{https://appropriate-link.com}}}

    \title{Melanoma Feature Representation between Human Experts and Neural Networks}
    \shorttitle{}
    \author{Murray S. Bennett}
\authorsnames{Murray~S.~Bennett, Joseph~W.~Houpt}
\authorsaffiliations{Department of Psychology, The University of Texas at San Antonio}

% \authornote{Correspondence should be sent to Murray S. Bennett, Department of Psychology, The University of Texas at San Antonio, Texas, United States. Email may be sent to murray.bennett@utsa.edu. Code for reproducing the analysis can be found at: \linkosf.}

\abstract{Melanoma is a deadly skin cancer, and early detection is critical for improving survival rates. Dermatologists typically rely on a visual scan to diagnose melanoma by assessing the primary perceptual characteristics of a skin lesion. The common ABCDE heuristic, for example, suggests observers check a lesion for shape (A)symmetry, (B)order irregularity, number of unique (C)olours, and (E)volution over time. Whilst this heuristic provides a practical guide, it is a limited approach. Firstly, all lesions vary and often contain only a subset of these features. Secondly, a combination of abnormal features can lead to a diagnosis, making the diagnostic process complicated and error-prone. Advanced computer vision algorithms (CVA) have emerged as a powerful approach to melanoma identification. CVAs can evaluate lesion features to generate highly accurate and objective assessments. However, despite CVA advancements, they can only be used in conjunction with an expert assessment. Thus, the perceptual expertise of dermatologists remains a critical component in the accurate and timely detection of melanoma. Our project aims to improve the early detection of melanoma by investigating the perceptual judgements of skin lesion colour and shape made by humans and comparing them with the feature representations generated by computer vision algorithms. We recruited non-expert participants online to complete a two-alternative forced-choice task using skin lesion images from the ISIC archive. Participants were instructed to choose the image that exhibited a greater frequency of unique colours in one condition and greater border regularity in another among the two images presented in a trial. We analysed the data using the Bradley-Terry-Luce (BTL) model to estimate each lesion image's relative "strengths" along these perceptual dimensions. We then compared these estimates to computer vision assessments of the same perceptual features. We discuss the methodological approach, preliminary results, and future directions.}

\keywords{computer vision, visual perception, melanoma identification, two-alternative forced choice, Bradley Terry Luce model}

\begin{document}
\maketitle

\setlength{\parskip}{0pt}


\section{Significance statement}

\newpage
\section{Research Question / Aim}
Do human perceptual judgements of skin lesion features differ from computer vision algorithms?
How are the perceptual features of skin lesions combined to generate diagnostic decisions of melanoma?
How are the perceptual features of skin lesions integrated when diagnosing melanoma?
How does expertise affect the integration of perceptual information in melanoma diagnosis?

Do human perceptual judgements of skin lesion asymmetry, border regularity, and colour variability differ to computer vision algorithm assessments?

\section{What we did}
We conducted a series of 2AFC tasks where pairs of skin lesions were presented side-by-side for participants to select the image they perceived to be greater along a prompted perceptual dimension. Specifically, we asked participants to evaluate images according to lesion symmetry, border regularity, and colour variance. We applied the Bradley-Terry-Luce model to these perceptual judgements to produce a scaled ranking of the relative perceptual strengths of each image along each of the assessed perceptual dimensions. We then applied computer vision algorithms to produce objective assessments of these features, and compared these assessments to human judgements.

\section{What we found}


\section{What it means}


\section{Take-Home message}


\section{Future direction}
Complete data collection on the current dimension, and expand to other valued dimensions: colour, size

More advanced computer vision assessment for the evaluation of features and for the segmentation of lesions.

This currently represents a descriptive examination of a single perceptual dimension. Our ambition is to begin an evaluation of features when combined. For example, we could readily expect the perception of border regularity to be affected by lesion size. Whilst we don't have the ground truth for lesion size (e.g., two masks may be the same size because the photographer zooms in, when in reality the two lesions are quite different), we can still provide a proof of concept here by relating the mask size to the BTL scaling.

Actual relationship to melanoma identification -- currently only looking at perception of real-world stimuli.

How does a GRT representation actually map to human perception?


\newpage


\section{Introduction}

\section{Methods}
\subsection{Participants}
Naive observers were recruited via the University of Texas at San Antonio (UTSA) undergraduate participant pool ($N= $). Participants were allocated randomly to one of the six conditions upon entry to the experiment. Demographic information was not collected. The study was approved by the IRB at UTSA (FY22-23-82). 

The final data analysis was conducted on $x_{1}$, $x_{2}$, $x_{3}$, $x_{4}$, $x_{5}$, and $x_{6}$ participants in the symmetrical, asymmetrical,  consistent border, irregular border, colourful, and uniform colour conditions. 

\subsection{Design}
We recorded the competitors in each trial, the winner and loser, and the response time for the decision. The experiment was divided into 4 conditions by isolating two dimensions of interest: border regularity and colour, then accessing each dimension from opposite ends of the feature scale. For example, colour was identified as a meaningful dimension, so participants were presented image pairs and in one condition, asked which was the \textit{colourful} whereas in another condition were asked which lesion had the more \textit{uniform} colour. Similarly, participants were asked to assess border irregularity in one condition and border consistency in another.
\
\subsection{Materials}
Images were selected from the International Skin Imaging Collaboration archive (ISIC). The ISIC archive contained approximately $71, 671$ images at time of retrieval (February, 2023). Metadata that included melanoma status, unique lesion identification numbers, and various patient demographic information accompanied all images. Duplicate images were removed ($n = 860$; see \cite{cassidy2022analysis}). We subjected the remaining $70, 611$ images to our computer-vision pipeline (see Analysis section), thus producing computer-vision measures of asymmetry, border regularity, and colour variance for all images. We then ranked the images and sorted according to the computer-vision assessments of border regularity. Images with border regularity scores greater than 0.9 or less than 0.1 were excluded. All $n$ remaining skin lesions with a melanoma diagnosis were included for the experiment sample, and the remaining $10,000 - n$ images were selected from the ranked image set via random-normal sampling to produce a final stimulus set size of $10, 000$ images. Images presented during the experiment were first rotated as required to present the longest image border along the horizontal axis then resized to $512\times384$px. 

\subsection{Procedure}

\subsection{Analysis}
\subsubsection{Computer Vision Pipeline}%
We applied a segmentation algorithm to all images prior to shape and colour assessments. PROVIDE DETAILS ON: Images were resized to $256\times192$px, image smoothing, hair/artefact removal, colour transformation, canny edge detection, 

I would suggest googling some of these functions to help clarify the process. You should also generate a separate document that specifies this procedure, and ensure that it's recreatable. Further, upload this to OSF.

1. hair removal
    a. grayscale
    b. blackhat morphological filtering -- (morphologyEx(cv.MORPH_BLACKHAT,...)
    c. closing -- morphologyEx(cv.MORPH_CLOSE,..)
    d. gaussian blurring
    e. intensify the idnetified hair/artefact contours for inpainting
    f. inpaint -- cv.inpaint(..,..,.., cv.INPAINT_TELEA)
2. colour clustering
    a. cv.medianBlur()
    b. kmeans cluster the image to 7 clusters.
3. clahe colour transformation -- contrast limited adaptive histogram equalisation
    a.  cv.createCLAHE
    b. convert to HSV
    c. apply clahe to each colour layer (H, S, and V)
    d. recombine layers and convert back to BGR colour space.
4. otsu segment
    a. otsu_thresh
        i. convert BGR to HSV (3d. not required)
        ii. use only the saturation and value layers.
        iii. apply gaussian blur
        iv. threshold the image using cv.threshold(img, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)
        v. canny edge detection -- cv.Canny(threshold, 100, 200)
        vi. dilate the contours to 'smooth' -- cv.dilate(canny_edge, kernel, iters=1)
    b. extract largest contour
    c. retrieve contour mask

\subsubsection{Bradley-Terry-Luce Model}%
\label{ssub:Bradley-Terry-Luce Model}


\section{Results}


\section{Discussion}

































Malignant melanoma affects this many people each year, and rates are increasing relative to the population. Early detection of melanoma improves survival rates by a huge amount.

The ability to detect melanoma and differentiate from benign lesions is critical. 

General heuristics used by experts, and suggested to the general public, include the ABCDE rule or the ugly duckling rule (if it looks suspicious, it probably is). 


However, these are only guides, and no sure-fire method for detecting melanoma, particularly during the critical, but difficult-to-detect early stages of melanoma growth, exists. 

Dermatology experience is a clear factor in diagnostic performance. 

Machine learning and image processing advances also represent practical and powerful methods for identification of images or collaborative suggestions in conjunction with trained dermatologists. 

Whilst the power of machine learning algorithms, image processing, and the list of identifiable features derived by algorithms for machine learning inputs continues to grow, the importance of trained specialists has

\subsection{Melanoma Identification}
\subsubsection{Artificial Intelligence}
We focus on the ABCD guidelines here as this heuristic lends itself to the approach taught to and used by human observers. 

\subsubsection{Human Performance}
\subsection{The Current Research}
\subsubsection{General Recognition Theory}
\subsubsection{Determination of Appropriate Stimuli}
\section{Experiment 1}
Image processing for baseline measures were conducted and tested against the ISIC-2017 challenge data, where stimulus performance on image segmentation was the goal. $\approx2000$ images with expert-consensus masks were provided for the challenge. We use this dataset as a benchmark for our own image segmentation algorithm, which can then be applied to other images, if need be. I think I might need to because the 2017 data only has melanoma classifications, and ground-truth representations of the melanoma segments. On the other hand, the ISIC database contains size measurements, that can be used to help with the \textit{D} metric. 

\subsection{Analytical Approach to Feature Identification}
Image processing and contour extraction to evaluate shape characteristics, such as border irregularity and asymmetry. There are a number of shape features that can be analysed or assessed in relation to the shape of the melanoma.

\subsection{Neural Net Approach to Feature Identification}
Some neural networks have been trained on/for the ABCD rule. 
We can use neural networks for image segmentation, the focus of the ISIC-2017 part 1 challenge. We can then take the segmentations and apply the same shape evaluations. 

\subsubsection{Human Ratings}
We can also take human ratings of stimulus features to determine feature scores for each stimulus. This approach to feature rating is subjective, particularly when human-raters are not experts within the field. The issue is compounded by the nature of the stimuli features we aim to rate. That is, perceptual concepts such as symmetry, border regularity, and color spaces are unclear, ambiguous, and other times entirely indiscernible. However, statistical machinery exists that allows the features of a stimulus to be scored on these perceptual dimensions relative to other stimuli. The Bradley Terry Luce model (BTL) estimates the probability that one item is greater than another, for all items in the set. Importantly, not all items of the set are required to be compared to determine a ranking. A novel application, and entertaining example application of the BTL is in the ranking of sporting teams in leagues where not all teams are able to compete against the other. 

The model requires an outcome score between items $i$ and $j$. In the current study, for example, a participant is presented with two skin lesion images and is asked to select the image that is more symmetrical of the two. The selected stimulus is recorded as the ``winner'' of the match-up between these items. 

% \begin{table}[]
% \centering
% \caption{Bradley-Terry-Luce Model dummy data}
% \label{table:BTL}
% \begin{tabular}{llllll}
%  &  & \multicolumn{4}{l}{vs Matchup} \\ \cline{3-6} 
%  &  & $S_{1}$ & $S_{2}$ & \dots & $S_{n}$ \\ \cline{3-6} 
% \multicolumn{1}{l}{\multirow{4}{*}{n Wins}} & \multicolumn{1}{l|}{$S_{1}$} & - & 1 & \dots & 0 \\
%  & \multicolumn{1}{l|}{$S_{2}$} & 1 & - & \dots & 3 \\
%  & \multicolumn{1}{l|}{$\vdots$} & $\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ \\
%  & \multicolumn{1}{l|}{$S_{n}$} & 2 & 0 & \dots & -
% \end{tabular}
% \end{table}

[[[You could describe some features of the dummy data -- e.g., incomplete matchups, asymmetry in matchup scores e.g., A>B, B>A]]]

The BTL estimates the probability that $i > j$, denoted as $P(i>j)$, where $P(i,j)$ is estimated as: 
\begin{equation}
    P(i, j) = \frac{p_{i}}{p_{i} + p_{j}}
\end{equation}

The below equation generates the estimate $p_{i}$ for each stimulus $i$.
\begin{equation}
    p_{i} = \frac{W_{i}}{\Sigma_{j\neq i}\frac{w_{ij}+w_{ji}}{p_{i}+p_{j}}}
\end{equation}

BTL gives us relative image scores. That is, the difference of 0.1 on the scale is consistent regardless of where you are on the board. This is hugely helpful as you can select images that are a relative distance from each other, rather than a similar ``score-space'' (e.g., 4.3 -> 4.4 is the same as 8.8 -> 8.9).

\section{Methods}
\subsection{Participants}
10 million participants ($M_{age} = 35,\sigma_{age} = 10$) were recruited online via MTurk, with participants randomly allocated to one of the four conditions upon entry to the experiment. The final data analysis was conducted on $x_{1}$, $x_{2}$, $x_{3}$, and $x_{4}$ participants in the irregular border, consistent border, colourful, and uniform colour conditions. This research was approved by the Human Research Ethics Committee at the University of Texas at San Antonio.

\subsubsection{Design}
We recorded the competitors in each trial, the winner and loser, and the response time for the decision. The experiment was divided into 4 conditions by isolating two dimensions of interest: border regularity and colour, then accessing each dimension from opposite ends of the feature scale. For example, colour was identified as a meaningful dimension, so participants were presented image pairs and in one condition, asked which was the \textit{colourful} whereas in another condition were asked which lesion had the more \textit{uniform} colour. Similarly, participants were asked to assess border irregularity in one condition and border consistency in another.
\begin{table}[!htp]
\centering
\caption{Experiment Conditions}
\begin{tabular}{lll}
 & Low & High \\ \hline
\multicolumn{1}{l|}{Border} & Consistent & Irregular \\
\multicolumn{1}{l|}{Colour} & Uniform & Colourful
\end{tabular}
\end{table}

\section{Results}
\section{Discussion}

\subsection*{Acknowledgements}
\subsection*{Availability of Materials}
\newpage
\bibliography{refs.bib}

\end{document}

