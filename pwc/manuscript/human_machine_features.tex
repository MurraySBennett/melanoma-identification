\documentclass[
    man, 12pt, a4paper,
    donotrepeattitle, floatsintext, draftfirst
]{apa7}
% Packages
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[style=apa, backend=biber]{biblatex}
\addbibresource{./melrefs.bib}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{authblk}
\usepackage{hyperref}
\usepackage{setspace}
\setlength{\parindent}{0.5in}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{subcaption}
\usepackage[toc,page]{appendix}

% Preamble
    % \title{Combining Human Perceptual Judgements with Computer Vision Assessments of Melanoma Features Improves Diagnostic Performance}
    \title{Deriving ratio scale estimates of skin lesion features from human perceptual judgements}
    \shorttitle{Ratio scale estimates of skin lesion features}
    \authorsnames[1,1,2,3,4]{
        Murray S. Bennett,
        Joseph W. Houpt,
        James T. Townsend,
        Michael J. Wenger,
        Lawrence Mark
    }

    \authorsaffiliations{
        The University of Texas at San Antonio,
        {Indiana University, Bloomington},
        The University of Oklahoma,
        Indiana University Health
    }
    \authornote{
        \textbf{Correspondence:} Any correspondence may be directed to the authors by email: \href{murray.bennett@utsa.edu}{murray.bennett@utsa.edu} or mailed to 1 UTSA Circle, The University of Texas at San Antonio, San Antonio, Texas.
    }
    \note{
        \vfill
        \raggedright
        \textbf{Significance statement:} For a set of $10,000$ images, we derived quantitative ratio-scale estimates of shape symmetry, border regularity, and colour variance from human perceptual judgments. These estimates can be used to control feature variance for image selection in public health campaigns and perceptual expertise training paradigms. We additionally found a human-machine collective benefit when including these estimates in SVM classifier alongside computer vision estimates of the same features. 
    }
    \abstract{
        Early identification of malignant melanoma, the deadliest skin cancer, depends on accurate perceptual judgements of a skin lesion's morphological features. To aid novice observers in identifying potential melanoma, rules-based guides such as the ABCDE heuristic prompt evaluation of shape asymmetry (A), border irregularity (B), colour variance (C), diameter (D), and evolution over time (E). While such guides help raise awareness of the key characteristics of melanoma, skin lesions are highly variable natural stimuli that make accurate judgements difficult, especially during the early stages of melanoma development. The large natural variability of skin lesions often results in the use of only highly symptomatic lesions in training paradigms and public health campaigns, limiting the development of perceptual sensitivity in observers.
    }
    \keywords{Melanoma, human perception, computer vision, quantitative measurement}


% you currently portray CV as a bit of a fold-standard for comparison, but it's also got practical and theoretical implications regarding how features are used differntly.
% Introduction: better fit with conclusions -- human use features, machine use features - do we use same or distinct features. What information is used?

\begin{document}
    \maketitle \noindent
Malignant melanoma is the deadliest form of skin cancer, with an estimated 97,000 new cases and 8,000 deaths in 2023 in the United States alone \parencite{siegel2023cancer}. The number of melanoma-related deaths is increasing despite advances in public health campaigns, training, computer vision and machine learning methods \parencite{glazer2017analysis, svedman2016stage, rigel2010trends, gardner2019current}. Fortunately, the survival rate of melanoma increases when detected early \parencite{davis2019current, rigel2010evolution}, but melanoma identification is a complex perceptual task, particularly during the early stages of melanoma when the perceptual signals that distinguish benign from malignant lesions are unclear. Although dermatologists have highly accurate perceptual representations of melanoma, the layperson is often the first to evaluate their lesions \parencite{koh1992discovers}. Therefore, a practical approach to reducing the impact of melanoma is through improvements in the perceptual judgements made by novice observers, thereby reducing the time between initial detection and expert evaluation.

Current public health recommendations designed to help novices decide if a lesion requires dermatological intervention emphasise rule-based methods, where individuals receive a qualitative guideline with an exemplar skin lesion \parencite{branstrom2002laypersons, robinson2006skills}.
One common guide is the ABCD heuristic \parencite{abbasi2004early}, which prompts novice observers to judge morphological features of skin lesions for early signs of melanoma according to shape asymmetry (A), border irregularity (B), colour variance (C) and diameter greater than 6 mm (D).
If an observer determines that a skin lesion has violated one or a combination of these rules, they are encouraged to seek expert evaluation.
Although the ABCD heuristic is an easy-to-remember guide, evidence for their efficacy is mixed \parencite{branstrom2002laypersons, xu2016training}. One major limitation of using rules-based guides is that rules are difficult to evaluate objectively, particularly by a noisy human perceptual system that is presented with visually complex stimuli.
For example, using your newly acquired knowledge of the ABCD criteria, review the skin lesions in Figure~\ref{fig:eg_discrimination} and consider at which point that a lesion has become sufficiently abnormal in each perceptual dimension to warrant further action.

\begin{figure}[htb]
    \caption{Feature variance in melanoma discrimination. At which lesion would you decide each feature has become sufficiently abnormal?}
    \centering
    \includegraphics[width=0.95\textwidth, keepaspectratio]{./feature_variance.pdf}
    \label{fig:eg_discrimination}
    \figurenote{\textit{Spoiler} -- only the final two images of each row are melanoma!}
\end{figure}

{\color{red}
    While melanoma identification is a challenging perceptual task for novice observers, expert dermatologists routinely achieve highly accurate diagnoses using perceptual judgment.
    The difference in diagnostic accuracy can be attributed to novices' use of distinct perceptual features in their judgements in contrast to a dermatologists expert use of holistic perceptual representations of lesions \parencite{norman1989development, gachon2005first}.
    These results suggest the value of focusing on training perceptual expertise.
    If perceptual training is sufficiently efficient, a much higher proportion of front-line practitioners and laypersons can be trained, thereby increasing early detection.
    However, perceptual training materials, such as those used in ABCD guides, have thus far typically relied on highly symptomatic exemplars and small testing sets.
    The use of such images risks performance inflation and fails to test or train sensitivity for skin lesions most critical to early detection: those lesions with only marginal deviations.
    That is, while highly symptomatic images typically used in training concisely demonstrate categories and concepts, effective training of perceptual sensitivity for continuous features would use well-controlled real-world images that reflect a wider range of the symptomatic continuum.
}

The current study aims to generate a large set of skin lesion images containing continuous quantitative measures of skin lesion features that can be used broadly in melanoma research, from perceptual training, as described above, to machine learning and computer vision applications, as described below.
Two primary approaches to achieving this goal are generating metrics based on (i) computer vision methods and (ii) the human perceptual system.
Both approaches have strengths and weaknesses for consideration, which we briefly address here before outlining a proposed strategy and study that addresses these limitations.

{\color{red}
    Computer vision algorithms and machine learning methods provide a robust approach to evaluating skin lesion imagery.
    An appealing feature of computer vision algorithms is that an algorithm's specification determines the type of information and the manner by which this information is evaluated.
    Additionally, it is novel to process large numbers of images once an algorithm is determined.
    Computer vision algorithms can thereby generate reproducible, consistent, and objective measures of skin lesion features; and there exists a substantial corpus of research dedicated to exploring and refining computer vision algorithms that incorporate new features, vary how features are assessed, and how feature estimates ought to be combined to best identify melanoma \parencite{maglogiannis2009overview, majumder2019feature, saba2021computer,wu2022skin}.
    However, the strength of a computer vision algorithm is also its weakness: an algorithm is limited to the specific information it is designed to assess, leaving it unable to evaluate or combine additional information that a human perceptual system might readily incorporate.
    In sum, computer-vision approaches offer a powerful pathway forwards for melanoma identification, but the information represented by an algorithm and how the algorithm evaluated this information is unlikely to reflect the human perceptual system researchers aim to train.

    Therefore, the development of a continuous measurement scale of skin lesions features derived via human perceptual judgements offers (i) a powerful addition to perceptual training paradigms and (ii) a comparison metric to evaluate and contrast the information used by computer vision methods.
    However, generating such a measurement scale from human judgements is not a simple task: judgements elicited from human observers are subjective and traditional rating scale methods, where an observer rates the degree of an image for each feature \parencite[e.g., ][]{meyer1996interobserver, gunasti2008interrater, aldridge2011novice, zanotto2011visual}, require a substantial time and financial cost that becomes untenable for larger image sets.
    We propose an approach that mitigates these limitations, thereby providing future researchers with a practical framework to quickly and effectively incorporate continuous measures of human perception into their perceptual training or computer vision and machine-learning paradigms.
}

Following the approach taken by \cite{zhang2019establishing} to generate a similar measurement scale for the perceptual constructs of `openness' and `natural' for scene categorisation, we use the Bradley-Terry-Luce model \parencite[BTL; ][]{bradley1952rank} to estimate a ratio scale representation of the perceptual features of \textit{shape asymmetry}, \textit{border irregularity}, and \textit{colour variance}\footnote{Note that we do not address diameter (D) here as the images confound size perception.} using a large set of $10,000$ images drawn from the International Skin Imaging Collaboration archive \parencite{ISICref}.
In contrast to previous studies using rating scales, our approach uses a pairwise comparison task that allows many participants to complete many comparisons at a relatively small cost.
Participants judge image pairs according to a single perceptual characteristic (e.g., ``which lesion is more asymmetrical?''), and a continuous ratio score for the feature is derived from the results of these comparisons for each image.
In parallel, we designed a computer vision algorithm to generate objective measures of shape asymmetry, border irregularity, and colour variance with which we compare against this human-perception-derived ratio scale.
Finally, we trained three support vector machine classifiers (SVM) using (i) human perception scores, (ii) computer vision scores, and (iii) both sets of feature estimates and compared the diagnostic performance of these models to demonstrate and explore the utility of this approach.


\section{Methods}
\subsection{Participants}
A total of 319 participants were recruited via the undergraduate participant pool of the University of Texas at San Antonio (UTSA; $n=231$) and Prolific, an online recruitment platform ($n=88$). We awarded UTSA participants course credit and Prolific participants $\$6$ per hour. The IRB at UTSA approved this study (FY22-23-82).

\subsection{Design and Materials}
Participants completed a pairwise comparison task under one of six between-subject conditions. Two factors defined the six conditions: (i) the prompted perceptual feature (shape asymmetry, border irregularity, or colour variance) and (ii) the prompt wording, where the participant prompt for each of the three features was also reverse-worded (i.e., shape symmetry, border regularity, or colour uniformity).

This study used a pool of $10,000$ skin lesion images ($512\times384$px) drawn from the International Skin Imaging Collaboration. (See Supplementary Material \ref{appendix:cvpipe} for the image selection pipeline). Pairs of images were randomly selected with replacement for each trial and presented side by side to participants on their devices (see Figure~\ref{fig:pwc_demo}). The participants responded using keyboard input: \textit{z} for the left image and \textit{m} for the right image. We recorded the identity of the image and the participants' decision on each trial.

\begin{figure}[htb]
    \caption{Example pairwise comparison trial with feature prompt}
    \centering
    \includegraphics[width=0.8\textwidth]{./pwc_demo.pdf}
    \label{fig:pwc_demo}
\end{figure}

\subsection{Procedure}
Following informed consent, we informed participants that skin lesions are risk-assessed by inspecting specific perceptual features. Participants were presented pairs of images and instructed to select the image they perceived as \textit{greater} along the prompted dimensions. This prompt was included in the footer of the screen throughout the experiment (see Figure~\ref{fig:pwc_demo}). For example, participants in the irregular border condition were instructed to ``select which of the two lesions has the more irregular border''. A general description of the targeted feature was also provided (for example, ``an irregular border is uneven or inconsistent'').

Participants first completed $6$ demonstration trials. The demonstration trials presented low- and high-images along the prompted perceptual dimension. The computer vision algorithm identified these images, which the authors visually confirmed. Participants then completed the experimental phase in $8$ blocks of $50$ trials ($400$ total). Participants received a 10-second enforced break between blocks. The trials began with a blank screen interval of $1000$ ms, followed by a $500$ ms visual cue (+) on the centre screen.
The image pairs were presented for a maximum of $10$ seconds or until participants made a response.
The total completion time for a participant to judge 400 image-pairs was approximately $25$ minutes.

We provided response-speed feedback to the participants if a response was faster than $300$ ms or the maximum trial time elapsed. Warnings were also provided to participants between blocks if the proportion of fast and slow responses (timed-out trials) for the previous block was greater than $0.2$ (i.e., ten trials) or if the proportion of responses in the last block to the position of the left or right image was greater than $0.75$ (i.e., 38 trials).

\subsection{Analysis}
\subsubsection{Human feature perception}
The BTL model assumes that the probability of selecting one image over another maps to the ``perceptual strength'' of the lesion's features.
For example, a skin lesion with a highly irregular border has a larger probability to be selected than a lesion with a regular border. Formally, the feature-strength scores for both images in an image pair, $v_a, v_b$, maps to the probability that a participant chooses the first image, $\pi_{ab}$:
\[\pi_{ab} = \frac{v_a}{v_a + v_b}\]
{\color{red}
    Estimating feature-strength parameters for pairwise comparison data is facilitated by many existing open source packages that allow parameter estimation with more advanced analysis requirements \parencite[e.g.,][]{turner2012btl}.
    However, the feature strength estimation for the simple case presented here can also be generated via logistic regression, greatly simplifying the analysis requirements for implementation across a broad range of practical cases.
}

Trials with response times faster than 500ms were removed from the analysis and data were reverse-scored across opposing conditions (e.g., border regularity choices were reversed to align with border irregularity). A simulation analysis evaluating the number of trials required to generate a $97\%$ probability of a fully connected graph for $10,000$ images indicated a minimum target of $40,500$ trials per feature. Following data cleaning, we applied logistic regression with $40,831$ comparison trials for shape asymmetry, $41,149$ trials for border irregularity and $41,438$ for colour variance.

We examined the Spearman rank-order correlation between BTL-derived feature strength values and each feature's computer vision estimates (described in the following section).
Finally, we evaluated the diagnostic accuracy of the feature strength values and the computer vision estimates across three Support Vector Machine (SVM) classifier models.
Each SVM classifier used a different set of feature vectors as input: The first model used the BTL-derived scores, the second used the computer vision estimates, and the third SVM classifier used both the BTL and the computer vision estimates.
Diagnostic performance was compared with receiver operating characteristic (ROC) analysis.
We used a five-fold cross-validation method to estimate the performance of each SVM model.

\subsubsection{Computer Vision Algorithm}
We briefly describe the computer vision processing and feature estimation pipeline here, but see Supplementary Material \ref{appendix:cvpipe} for details. To generate skin lesion masks for shape and colour analysis, images were resized to $512x384$px and converted to HSV colour format. We then applied a hair-removal filter, followed by k-means ($k=6$) clustering and colour contrast enhancement (via CLAHE algorithm) before implementing Otsu segmentation. The final segmentation mask was used to estimate shape symmetry and border regularity, and the segmented skin lesion area was used to estimate colour variance.

Following \parencite{majumder2019feature}, shape symmetry was estimated as proportion of non-overlapping area when the lesion's mask was mirrored along the horizontal and vertical axes.
The final estimate was determined as the average proportion across these major axes.
A higher proportion of non-overlapping regions indicate poor symmetry.
For example, a mirrored circle would have complete overlapping halves.

We estimated border regularity using the compactness factor, which is defined as the ratio of the area of the skin lesion to the area of a circle with the same perimeter: compactness $ = \frac{4\pi A}{P^2}$, where $A$ is the area of the skin lesion mask and $P$ is its perimeter.
These raw estimates range from 0 to 1, with 1 being a circle - the most compact and symmetrical shape - then take the complement to align estimate interpretation, such that higher values represent greater border irregularity.
Finally, We used a continuous measure of colour variance estimated as the root mean square error of the RGB channels for the segmented skin lesion.
Each computer-vision estimate was then normalised to the range of the respective BTL-estimate for analysis.

\section{Results}
We evaluated the face validity of BTL estimated values for each feature by sorting images by their BTL-rank and examining the ordered images. Figure~\ref{fig:btl_fv} summarises this inspection process and presents skin lesion images with high, moderate, and low feature strength values for shape asymmetry (left), border irregularity (middle) and colour variance (right).

% shape asymmetry
% high
Skin lesions with high shape asymmetry included images with inconsistent interior structures and colour, multiple lesions, or poorly defined borders.
% low
Images with low asymmetry (i.e., high symmetry) also contained substantial colour variance. Still, the lesion shapes tended to be circular or, interestingly, elliptical, indicating that judgements of shape symmetry were, in some cases, made according to a single plane (e.g., along the horizontal or vertical axis).

% border irregularity
% high
The skin lesions judged to have high border irregularity included three types: skin lesions with (i) smooth but irregular boundaries, (ii) indistinct or soft boundaries, or lesions that shared these characteristics.
% low
In contrast, distinct, compact, and circular lesions with uniform colouration represented low border regularity.

% colour variation
% high
Images with high colour variance had multiple interior colours, with distinct differences between colours (e.g., reds, dark vs. light brown). In contrast, skin lesion images with low colour variance had consistent interior colour, albeit different colours between images. A low colour variance image might have had dark or light pigmentation, but the entire lesion contained the same colouration.

\begin{figure}[tbh]
    \caption{Face validity demonstration of Bradley-Terry-Luce model feature-strength estimates.}
    \label{fig:btl_fv}
    \includegraphics[width=\textwidth,keepaspectratio]{./btl_facevalidity.pdf}
    \figurenote{Skin lesion images with higher BTL feature values for shape asymmetry, border irregularity, and colour variance are shown across the top rows of the figure versus. Lesions estimated to have lower perceptual strength are shown along the bottom rows.}
\end{figure}

We examined the Spearman correlation between all BTL model-derived feature strength values, the computer vision estimates, and malignancy via Pearson correlation.
These results are shown in Figure~\ref{fig:corr_mat}, but we focus on the correlation between BTL strength scores and computer vision estimates of shape asymmetry, border irregularity, and colour variance (see Figure~\ref{fig:corr}).
We found a positive and significant relationship between all three feature comparisons, but of varying correlational strength: shape asymmetry ($\rho = 0.42, p < 0.001$) and border irregularity ($\rho = 0.406, p < 0.001$) both indicated moderate strength relationships, while colour variance ($\rho = 0.052, p < 0.001$) showed a weak positive relationship.
These results suggest that human and computer vision observers share similar but imperfect representations of the target features.
\begin{figure}[tbh]
\begin{subfigure}{\textwidth}
    \caption{BTL feature strength and computer vision estimate correlations.}
    \label{fig:corr}
    \centering
    \includegraphics[width=\textwidth]{./btl_cv_cor.pdf}
    \figurenote{Spearman correlation between the skin lesion feature estimates based on human judgements and computer vision estimates for shape asymmetry, border irregularity, and colour variance. The complete correlation matrix between all features (Spearman) and malignancy (Pearson) is included in Figure~\ref{fig:corr_mat}.}
\end{subfigure}
\begin{subfigure}{\textwidth}
    \caption{Full correlation matrix between BTL feature strengths and computer vision (CV) estimates (shape asymmetry (A), border irregularity (B) and colour variance(C)), and malignancy.}
    \label{fig:corr_mat}
    \centering
    \includegraphics[width=0.5\textwidth,trim={0.3cm 0.2cm 1.7cm 1.6cm}, clip]{./btl_cv_cor_mat.pdf}
    \end{subfigure}
\end{figure}

We trained three Support Vector Machine (SVM) models using (i) BTL feature strength values, (ii) computer vision estimates, or (iii) both feature sets to predict skin lesion malignancy.
We evaluated how the different feature sets affected classification performance by comparing areas under ROC curves.
Figure~\ref{fig:svm} displays the ROC curves and AUC scores for the three models against a random performance benchmark.
The model trained on the estimates of computer vision features produced greater diagnostic discrimination ($AUC = 0.82$) than the model trained on the BTL-derived feature strengths ($AUC = 0.78$).
However, of most interest, the SVM classifier that used \textit{both} the BTL feature strength values and the computer vision estimates generated the highest diagnostic classification ($AUC = 0.86$), indicating an improvement in diagnostic performance when combining human perceptual judgements and computer vision estimates of ABC features.

\begin{figure}[tbh]
    \caption{Support Vector Machine ROC curves.}
    \label{fig:svm}
    \begin{center}
        \includegraphics[width=0.6\textwidth]{./SVM_ROC.pdf}
    \end{center}
    \figurenote{AUC values approaching $1$ and ROC curves tending toward the top-left of the figure indicates greater diagnostic classification performance.}
\end{figure}

\section{Discussion}
Rates of melanoma, the deadliest form of skin cancer, are rising. There are two primary approaches to improving the early detection of melanoma, thereby reducing its impact: (i) public awareness campaigns and (ii) developing an observers perceptual expertise. Critically, these approaches rely on the use of highly symptomatic skin lesions to exemplify important perceptual features. For example, the ABCD guide frequently used in public health campaigns highlights shape asymmetry, border regularity, and colour variance, and perceptual training paradigms for the categorisation of different skin cancers use lesions that exemplify each category. The use of skin lesion images in either of these approaches that account for the large perceptual variability of the lesion's distinguishing morphological features may improve the overall efficacy of these approaches. The current study aimed to generate quantitative ratio-scale measures of shape symmetry, border regularity, and colour variance that are derived from human perceptual judgements.

To this end, we collected pair-wise comparison judgements of shape symmetry, border regularity, and colour variance with a set of $10,000$ skin lesion images from the online ISIC archive. Quantitative ratio-scale `feature strength' scores were derived from this data using the Bradley-Terry-Luce model (BTL) and compared against objective computer-vision estimates of the same features. We then evaluated the diagnostic discriminability of the two feature estimation approaches via comparison across three support vector machine models (SVM) that each used a different combination of features: (i) BTL derived feature strength scores, (ii) computer vision estimates, and (iii) both BTL and computer vision estimates. While the SVM model trained on the computer vision estimates outperformed the model trained on human-perception BTL scores, we found the greatest diagnostic discrimination was produced by the model that used both the computer vision and human-perception estimates, indicating a human-machine collaborative benefit.

Overall, this study presents two primary outcomes. The first is practical. Judgements of skin lesion features by human observers often carry a high time and cost demand. Our pairwise-comparison task with the BTL model estimation circumvents these limitations. The practical outcome is the curation of a set of $10,000$ images, each with a quantitative ratio-scale measure of its human-perceived shape symmetry, border regularity, and colour variance. Furthermore, each image is also accompanied by our computer-vision estimates of these features, which are readily accessible for future practical application or in research pursuits, such as benchmarking and comparison between computer-vision algorithms.

Future studies adopting this design could evaluate additional perceptual features to complement the existing estimates. For example, the current study examine shape symmetry, border regularity, and colour variance based upon the popular ABCD criteria, but there are many other perceptual features that are important in making melanoma diagnoses (e.g., lesion texture, skin colour etc.). Additionally, the pairwise comparison task reported here is a highly generalisable approach that is readily adapted to the current needs of the researcher. While we have generated a large image bank and encourage its use, researchers should not feel compelled to move away from their existing image sets if they have them. Researchers might instead look to incorporate a brief pairwise comparison design to quickly and cost-effectively generate human-perception estimates of their existing skin lesion images that are relevant to their research goals. A perceptual learning task aimed at training skin cancer category discrimination (\`a la \cite{kellman2023connecting}), for example, can with relative ease generate continuous estimates of category representativeness of their images, thereby allowing greater control over the images selected for training.

The second primary outcome is both practical and theoretical. Our comparison between SVM models (see Figure~\ref{fig:svm}) revealed a human-machine collaborative benefit in melanoma diagnosis. That is, an SVM model trained using both computer-vision estimates \textit{and} feature estimates derived from human perceptual judgments resulted in greater diagnostic accuracy than either of the SVM models trained using \textit{only} the computer vision or BTL estimates. This performance benefit represents an important consideration in how researchers and the public approach, evaluate, and rely upon computational methods, particularly in melanoma identification tools, but also more broadly across other fields of perceptual science as well as domains that rely upon human expertise. Concretely, while computational approaches may outperform humans on a given task, methods that incorporate human expertise with such approaches may further improve overall performance.

An important consideration, however, is that the feature estimates of our study were derived from the perceptual judgements of \textit{novice} observers. Along with having explicit training on the subject matter, expert perception is typically exemplified by configural or holistic processing of perceptual information, whereas novice observers use distinct features \parencite{garrett2022wheel}. It is then reasonable to expect differences in the judgments made of these images by an expert observer (i.e., a dermatologist). However, it is valuable to note that participants were only prompted to judge a single feature, not to make \textit{diagnostic} judgements. This distinction may reduce the potential differences between novice and expert judgements of these features, but an empirical examination comparing the feature judgements of expert and novice observers is required to determine the extent of this limitation.

Finally, while participants made judgements of single features, as per the ABCD guidelines, human perceptual processing is fundamentally multidimensional. Although a participant is asked to judge a lesion according to its symmetry, it is unclear if, and to what extent, these judgements are affected by the degree or `strength' of the other perceptual features. For example, consider two skin lesions with the same level of shape symmetry, but one lesion has a more irregular border than the other. Is shape symmetry perceived in the same way regardless of the level of border regularity, or does the degree of border regularity interact with our perception of shape symmetry? The interaction between perceptual dimensions and the effects upon decision-making is an important question in perceptual science, and has stark implications here in melanoma identification. An investigation of the presence or extent of the interactions between perceptual dimensions is critical to understanding the cognitive and perceptual processes involved in the judgements of skin lesions, and is the focus of the authors' ongoing research \parencite{ourgrt2024preprint}.

\subsection{Conclusion}
% add references into your conclusion, you dolt.
The current study aimed to generate a continuous quantitative measure of the morphological features used for melanoma identification that is based on the human perceptual system. Based on the popular ABCD heuristic, we specifically examine shape symmetry, border regularity, and colour variance. We implemented a pairwise comparison design with a bank of $10,000$ skin lesion images and applied the Bradley-Terry-Luce model to derive ratio-scale estimates of the perceptual strength of each image's features. We compared the BTL estimates to those made by a computer-vision algorithm. We then evaluated the diagnostic performance of these feature estimates across three SVM models that were trained using (i) BTL estimates, (ii) computer vision estimates, or (iii) both BTL and CV estimates.

We found classification performance was greatest when an SVM model was trained using both human and computer estimates of the shape symmetry, border regularity, and colour variance features. This human-machine collective benefit, where the combination of the BTL-derived and computer vision estimates led to greater diagnostic performance, highlights the value of human perceptual judgements, even more so given that these estimates were derived from novice observers. We encourage future researchers and designers using computer vision algorithms or machine learning technology to consider the inclusion of human perceptual in their research and programmatic designs.

Finally, and of the greatest practical value, we generated human-perception based estimates of feature strength for a bank of $10,000$ skin lesion images that are available for use by the research community. Our demonstration of these features in training SVM classifiers is one example of how such features may be used, but the applications of such estimates are far-reaching. Controlling the feature variance across images used in dynamic training paradigms is one such example. For the many cases where our estimates and image bank do not apply, we instead encourage the use of the pairwise comparison design for researchers to quickly and cheaply generate continuous scale estimates of their existing images or phenomena of interest.


\newpage
\printbibliography

\newpage
\appendix
\section{Image extraction and computer vision pipeline}
\label{appendix:cvpipe}
The ISIC archive contained approximately $71, 671$ images at time of retrieval (February, 2023). Metadata that included melanoma status, unique lesion identification numbers, and various patient demographic information accompanied all images. Duplicate images were removed ($n = 860$; see \textcite{cassidy2022analysis}). We subjected the remaining $70, 611$ images to our computer-vision feature extraction pipeline (see Analysis section), thus producing computer-vision measures of asymmetry, border irregularity, and colour variance for all images. We ranked the images and sorted according to the computer-vision assessments of border irregularity. Images with border regularity scores greater than 0.9 or less than 0.1 were excluded. All $n$ remaining melanoma images diagnosis were included for the experiment sample, and the remaining $10,000 - n$ images were selected from the ranked image set via random-normal sampling to produce a final stimulus set size of $10, 000$ images. Images presented during the experiment were rotated as required to present the longest image border along the horizontal axis then resized to $512\times384$px.

\begin{figure}
    \centering
    % trim{left bottom right top}
    \includegraphics[width=0.9\paperwidth,keepaspectratio,trim={2.5cm 12.5cm 1cm 1cm}, clip]{cv_pipeline.pdf}
    \caption[Computer vision pipeline]{Computer vision image processing pipeline. Images proceed through four stages: (i) a hair removal and artefact reduction filter, (ii) colour contrast is then enhanced before (iii) the segmentation process and mask generation for (iv) feature extraction.}
    \label{fig:cv}
\end{figure}


\end{document}