---
title: "BTL-Simulations"
output: html_document
date: "2023-03-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Aim 

The analysis contained herein aims to determine some useful suggestion of sample size for an upcoming experiment. The experiment is a 2-alternative forced choice task. Participants will be presented with images of skin lesions with the direction to select the image that most represents some perceptual feature. For example, "which lesion has the more uniform colour?" or "which lesion has the more irregular border?". This design can be conceptualised as a series of 'contests' with a winner and a loser on each trial. Under this conceptualisation, we can then apply the Bradley-Terry-Luce model to estimate the *ability* of each stimulus on these perceptual dimensions, thereby allowing a rank-ordering of stimuli. A true strength of this approach is that the differences between item abilities is *relative*, which allows future researchers to select specific stimuli appropriate to their research goals.

The image set we are working with comes from the [ISIC archive]( https://www.isic-archive.com), which contains some 71, 000 images. Generating abilities and ranks for all images within this database represents a substantial endeavour. Specifically, the number of match-ups required to connect all items to reliably estimate the true item abilities would require a large amount of contests. The upcoming simulations aim to address this issue.

``` {r load_library, message=FALSE}

library(BradleyTerryScalable)
# library(ggplot2)
# library(dplyr)
# library(furrr)
library(tidyverse)
library(Matrix)
library(igraph)
library(hrbrthemes)
library(tictoc)
```

```{r simulation_demo, message=FALSE, warning=FALSE}
set.seed(1989)
n_items <- 10
# contests_per_pair <- 1
mean_contests_per_pair <- 1
## Generate at random a sparse, symmetric matrix of binomial totals: 
# n_trials <- rpois(n = n_items * (n_items - 1) / 2, lambda = 1)
contests <- rpois(n=n_items, lambda = mean_contests_per_pair)
notzero <- contests > 0
Nmatrix <- Matrix(nrow = n_items, ncol = n_items)

# You would use this nmatrix if you expected every pair to be exposed once
# Nmatrix <- matrix(data=contests_per_pair,nrow=n_items, ncol=n_items)
ij <- which(lower.tri(Nmatrix), arr.ind = TRUE)[notzero, ]
Nmatrix <- sparseMatrix(
             i = ij[, 1],
             j = ij[, 2],
             x = contests[notzero],
             symmetric = TRUE,
             dims = c(n_items, n_items))

## Generate at random the (normalized to mean 1) 'player abilities':
pi_vec <- exp(rnorm(n_items) / 4)
pi_vec <- pi_vec / mean(pi_vec)

## Now generate contest outcome counts from the Bradley-Terry model:
big_matrix <- simulate_BT(pi_vec, Nmatrix, nsim = 1, seed = 1)[[1]]
big_btdata <- btdata(big_matrix, return_graph = TRUE)


## Fit the Bradley-Terry model to the simulated data:
the_model <- btfit(big_btdata, a = 1)
pi_fitted <- the_model $ pi $ full_dataset

## calculate RMSE
actual = log(pi_vec[as.numeric(names(pi_fitted))])
predicted = log(pi_fitted)
predicted[is.infinite(predicted)] <- NA

# Metrics
rmse = sqrt(mean(actual - predicted, na.rm=TRUE)^2)
n_trials_simulated = sum(big_matrix)
n_unique_graphs = length(the_model$diagonal)
```

```{r, figures-side, fig.show="hold", out.width="30%", message=FALSE, warning=FALSE, echo=FALSE}
## Plot fitted vs true abilities:
plot_df <- tibble(x = log(pi_vec[as.numeric(names(pi_fitted))]),
                  y = log(pi_fitted))

par(mar = c(4, 4, .1, .1))

ggplot(plot_df, aes(x, y)) +
  geom_point(alpha = 0.5) +
  geom_abline() +
  annotate("text", x=0, y=0, label=paste("RMSE =", round(rmse, 4)), colour='red') +
  xlab("true strength") +
  ylab("maximum likelihood estimate") +
  ggtitle(paste(n_items,"-item simulation with ", n_trials_simulated, " trials.", sep="")) +
  theme(plot.title = element_text(hjust = 0.5))

plot.igraph(big_btdata$graph, vertext.size= 20, edge.arrow.size = 1)

x <- as.character(seq(1, n_items))
y <- as.character(seq(1, n_items))
hm <- expand.grid(X=x, Y=y)
hm$Z <- matrix(big_matrix, dimnames=list(t(outer(colnames(big_matrix), rownames(big_matrix), FUN=paste)), NULL))

# Heatmap 
ggplot(hm, aes(X, Y, fill= Z)) + 
  geom_tile() + 
  scale_fill_distiller(palette = "RdPu") +
  theme_ipsum()

```
## Simulations
Run x simulations
Collect RMSE, the number of complete networks, and the number of trials simulated.

``` {r, Simulation Paramters, warning=FALSE, message=FALSE}
n_sims = 1000

items_max = 21
items_step= 10
n_items = seq(10, items_max, items_step)

mean_contests_per_pair = c(1, 5) #c(0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10, 15, 20)

sim_col_names = c("mu", "sd", "med", "se", "n_sims", "mean_ij_contests", "n_items", "trials", "iter")

r = length(n_items) * length(mean_contests_per_pair)
c = length(sim_col_names)

rmse_desc = data.frame(matrix(ncol=c, nrow=r, dimnames=list(NULL, sim_col_names)))
graphs_desc = rmse_desc
order_error_desc = rmse_desc
p_corr_desc = rmse_desc
```

``` {r, descriptive functions, echo=FALSE}

get_desc <- function(array){
  mean_val <- mean(array, na.rm=TRUE)
  sd_val <- sd(array, na.rm=TRUE)
  med_val <- median(array, na.rm=TRUE)
  se_val <- sd_val / sqrt(length(array))
  return (c(mean_val, sd_val, med_val, se_val))
}

return_sim_parms <- function(n_sims, mean_contests, n_items, trials, iteration_count){
  # return(c("n_sims" = n_sims, "mean_ij_contests" = mean_contests, "n_items"=n_items, "iter"=iteration_count))
  return(c(n_sims, mean_contests, n_items, trials, iteration_count))
}
```

``` {r, run sims, echo=FALSE}
set.seed(1989)
tic() # 1000 sims runtime with 2 levels of eaach i and c = 18.54sec
sim_counter = 0

for (i in n_items){
  for (c in mean_contests_per_pair){
    contests <- rpois(n=i, lambda = c)
    notzero <- contests > 0
    Nmatrix <- Matrix(nrow = i, ncol = i)
    
    ij <- which(lower.tri(Nmatrix), arr.ind = TRUE)[notzero, ]
    Nmatrix <- sparseMatrix(
                 i = ij[, 1],
                 j = ij[, 2],
                 x = contests[notzero],
                 symmetric = TRUE,
                 dims = c(i, i))
    
    ## Generate at random the (normalized to mean 1) 'player abilities':
    pi_vec <- exp(rnorm(i) / 4)
    pi_vec <- pi_vec / mean(pi_vec)
    
    ## Now generate contest outcome counts from the Bradley-Terry model:
    big_matrices <- simulate_BT(pi_vec, Nmatrix, nsim = n_sims, seed = 1)
    
    for (m in 1:n_sims){
      # print(sum(big_matrices[[m]]))
      big_matrix <- big_matrices[[m]]
    
      big_btdata <- btdata(big_matrix, return_graph = TRUE)
    
    
      ## Fit the Bradley-Terry model to the simulated data:
      the_model <- btfit(big_btdata, a = 1)
      pi_fitted <- the_model $ pi $ full_dataset
    
      ## calculate RMSE
      actual = log(pi_vec[as.numeric(names(pi_fitted))])
      predicted = log(pi_fitted)
      predicted[is.infinite(predicted)] <- NA
    
      # Metrics
      rmse[m] = sqrt(mean((actual - predicted)^2, na.rm=TRUE))
      trials = sum(big_matrix)
      n_unique_graphs[m] = length(the_model$diagonal)
      act_ordered = length(actual) - order(actual) + 1
      pred_ordered= length(predicted) - order(predicted) + 1
      order_err[m] = sqrt(mean((act_ordered - pred_ordered)^2, na.rm=TRUE))
      p_corr[m] = cor(actual, predicted, method="pearson", use = "complete.obs")
      # print(sprintf("RMSE: %s, n-trials: %s, unique graphs: %s, order error: %s, p-corr: %s", round(rmse,4), n_trials_simulated, n_unique_graphs, round(order_err,4), round(p_corr,4)))
    }
    sim_counter = sim_counter + 1
  
  
    rmse_desc[sim_counter,] = c(get_desc(rmse), return_sim_parms(n_sims, c, i, mean(trials), sim_counter))
    graphs_desc[sim_counter,] = c(get_desc(n_unique_graphs), return_sim_parms(n_sims, c, i, mean(trials), sim_counter))
    order_error_desc[sim_counter,] = c(get_desc(order_err), return_sim_parms(n_sims, c, i, mean(trials), sim_counter))
    p_corr_desc[sim_counter,] = c(get_desc(p_corr), return_sim_parms(n_sims, c, i, mean(trials), sim_counter))
  }
}
toc()
```
## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
